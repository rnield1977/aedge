Week 2 Notes
--------------------------------------------------------------------------------------
Out of sample SSE
SSE <- sum((PointsPrediction - NBA$PTS)^2)
SST <- sum((mean(NBA$PTS) - NBA_test$PTS)^2)
R2 <- 1 - SSE/SST
RMSE <- sqrt(SSE/nrow(NBA_test))

Relative Error
(Observed ILI - Estimated ILI)/Observed ILI

Use step() to find model

Week 3 Notes
--------------------------------------------------------------------------------------

Sensitivity
True Positives / True Positives + False Negatives

Specificity
True Negatives / True Negatives + False Positives

 TN FP
 FN TP

False Negative Error Rate = FN / TP+ FN
False Positive Error Rate = FP / TN + FP

To get the confusion Matrix 
table(qualityTrain$PoorCare, predictTrain > 0.5) 

    FALSE TRUE
  0    70    4 
  1    15   10
  
 
  
  Compute Sensitivity (Measure Classify Possitive Correctly)
  10/25
  
  Compute Specificity (Measure Classify Negative Correctly)
  70/74
  
Creating ROCR Example:
library(ROCR)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)
ROCRperf = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf, colorize="TRUE")
or 
plot(ROCRperf, colorize="TRUE", print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))

Area Under Curve
auc = as.numeric(performance(ROCRpred, "auc")@y.values)
    
    
#Using the Mice Package
library(mice)
imputed = complete(mice(simple))


#Better way of filtering based on columns
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
songsTrain = songsTrain[ , !(names(songsTrain) %in% nonvars) ]
OR
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)

use response on predictions

Get the Odds Ratios for each coef
exp(coef(mylogit))
Can do.
exp(cbind(OR = coef(mylogit), confint(mylogit)))

Steps for the odds ratio:
1- Take coef of the model -4.2411574 + 0.3869904*male + 0.8867192*race - 0.0001756*age + 0.4433007*state2 + 0.8349797*state3 - 3.3967878*state4 - 0.1238867*time.served + 0.0802954*max.sentence + 1.6119919*multiple.offenses + 0.6837143*crime2 - 0.2781054*crime3 - 0.0117627*crime4 =  -1.700629

2- Odds Ratio is OR <- exp(-1.700629)
3- Prediction probability
  1/(1+exp(1.700629))
  
  


Example 2 of Mice
vars.for.imputation = setdiff(names(loans), "not.fully.paid")
imputed = complete(mice(loans[vars.for.imputation]))
loans[vars.for.imputation] = imputed



Set Profit under Logistic regression probabilities.
> test$profit = exp(test$int.rate*3) - 1
> test$profit[test$not.fully.paid == 1] = -1


Example of sorting via a cutoff
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]

Week 4

Cart Example
library(rpart)
library(rpart.plot)
StevensTree <- rpart(Reverse ~ Circuit + Issue + Petitioner + respondent + LowerCourt + Unconst, data=train, method="class", minbucket=25)

prp(StevensTree)
PredictCart = predict(StevensTree, newdata=test, type="class")
table(test$Reverse, PredictCart)

PredictROC <- predict(StevensTree, newdata=test)
pred <- prediction(PredictROC[,2], test$Reverse)
perf <- performance(pred,"tpr","fpr")
plot(perf, colorize=TRUE)

as.numeric(performance(pred, "auc")@y.values)

Random Forrest
library(randomForest)
StevensForrest <- randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train, nodesize=25, ntree=200)
> PredictForest <- predict(StevensForest, newdata=test)
PredictForest <- predict(StevensForrest, newdata=test)


k-Fold Cross- Validation
cp is like R2 and AIC smaller is better
library(caret)
library(e1071)
numFolds <- trainControl(method="cv", number=10)
cpGrid <- expand.grid(.cp=seq(0.01,0.5,0.01))
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train, method="rpart", trControl=numFolds, tuneGrid=cpGrid)

StevensTreeCV <- rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train, method="class", cp=0.18 )

PredictCV <- predict(StevensTreeCV, newdata=test, type="class")
table(test$Reverse, PredictCV)

# To get precentage of of particular variable
Example:
table(Claims$bucket2009) / nrow(Claims)

#Penalty Matrix Example

PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)

as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)) * PenaltyMatrix

sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)) * PenaltyMatrix)/nrow(ClaimsTest)

#Example
We then want to get a higher then
(110138 + 10721 + 2774 + 1539 + 104 )/ nrow(ClaimsTest)
and lower then
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)) * PenaltyMatrix)/nrow(ClaimsTest)

--------------
Standard Basline
NOTE this is the first column of the matrix.
PM <- c(0,2,4,6,8)
table(ClaimsTest$bucket2009) * PM
sum(table(ClaimsTest$bucket2009) * PM) / nrow(ClaimsTest)


---------------
Example of plotting fitted value as well as adding $ to pch


---------------

Example of plot of final model using caret
best.tree <- tr$finalModel
prp(best.tree)

---------------
Example of logistic regression interaction
LogModel2 = glm(voting ~ sex + control + sex:control, data=gerber, family="binomial")


-----------------
When taking ROCR for CART be sure to remove type="class" when predicting


--------------
One metric that we can look at is the number of times, aggregated over all of the trees in the random forest model, that a certain variable is selected for a split. To view this metric, run the following lines of R code (replace "MODEL" with the name of your random forest model):

vu = varUsed(MODEL, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(MODEL$forest$xlevels[vusorted$ix]))


Show model impurity
A different metric we can look at is related to "impurity", which measures how homogenous each bucket or leaf of the tree is. In each tree in the forest, whenever we select a variable and perform a split, the impurity is decreased. Therefore, one way to measure the importance of a variable is to average the reduction in impurity, taken over all the times that variable is selected for splitting in all of the trees in the forest. To compute this metric, run the following command in R (replace "MODEL" with the name of your random forest model):
varImpPlot(MODEL)


-----------------------

